1.String date转LocalDateTime
DateUtil.parseLocalDateTime(String date);

2.异常类
BizAssert ApiResultFailEnum

3.LocalDateTime转Date
Date.from(now.atZone(ZoneId.systemDefault()).toInstant());
date转LocalDateTime
date.toInstant().atZone(ZoneId.systemDefault()).toLocalDateTime();

4.图像地址
ImageUtil.getImageUrl(orderSku.getSkuImgUri(), orderSku.getSkuImgUriType());

5.分转元，返回字符串
NumberUtil.intToBigDecimal(Integer number);
PriceUtil.fenToYuanStrTrailingZeros(long fenNum);

6.编程式事物作用代码块上，更颗粒化。
@Autowired
private TransactionTemplate transactionTemplate;
transactionTemplate.execute(transactionStatus -> {return Boolean.TRUE;});

7.LocalDateTime转String
DateUtil.formatLocalDateTime();
LocalDateTimeUtil.formatNormal();
 String转LocalDateTime
LocalDateTimeUtil.parse(time, "yyyy-MM-dd")

8.加密字符串16进制
SecureUtils.encryptStr(String content);

9.解密为字符串
SecureUtils.decryptStr(String content);

10.字符串忽略大小写
"a".equalsIgnoreCase("A");

11. redis工具类
@Resource
private JedisHelper jedisHelper;

12 阿里的JetCache分布式缓存redis锁 非阻塞获取锁
@CreateCache(name = "orderInfoPayTimeExpired:")
private Cache<String, String> orderInfoPayTimeExpiredCache;
orderInfoPayTimeExpiredCache.tryLockAndRun(K key, long expire, TimeUnit timeUnit, () -> {
});

13.空分页
PageDto.emptyPage();

14.判断集合是否为空
CollUtil.isNotEmpty();

15. 根据经纬度获取地址以及地势编码
http://api.map.baidu.com/geocoder?location=24.900957,118.601253&output=json

16. 字符串格式化
StrFormatter.format()

17. alibaba.fastjson格式化对象
JSON.parseObject(response, new TypeReference<ManagerResult<QueryOrderResultDto>>(){});

19. 根据时间天数计算当前之前的时间
LocalDate today = LocalDate.now();
LocalDate nextWeek = today.minus(90, ChronoUnit.DAYS);

20. 根据时间天数计算当前之后的时间
LocalDate today = LocalDate.now();
LocalDate nextWeek = today.plus(90, ChronoUnit.DAYS);

21. 百度地图根据GPS标准坐标(相对于比较准确)
http://api.map.baidu.com/reverse_geocoding/v3/?ak=iRedamZb8fqsESK2NGO0ecpQKxLZ2GUZ&output=json&coordtype=wgs84ll&location=31.325108,120.72347

22. new对象直接设置值
@Accessors(chain = true)

23. 获取客户端ip地址
HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();
ServletUtil.getClientIP(request)

24. hutool HttpRequest发送请求工具类
HashMap<String, Object> paramMap = new HashMap<>();
paramMap.put("token", token);
HttpRequest.post(USER_URL)
.header(Header.CONTENT_TYPE, "application/x-www-form-urlencoded")
.form(paramMap)
.execute()
.body();

JSONObject json = new JSONObject();
json.put("username", "1332788xxxxxx");
json.put("password", "123456.");
HttpRequest.post(USER_URL)
.header(Header.CONTENT_TYPE, "application/json")
.body(json)
.execute()
.body();

25. hutool HttpUtil请求
HttpResponse response = HttpUtil.createGet(url).execute().body();

26. list根据3000拆分
Lists.partition(list, 3000);

27. list转map
list.stream().collect(Collectors.toMap(Person::getId, Person::getName,(key1 , key2)-> key2 ));
list.stream().collect(Collectors.groupingBy(ProductRealSaleDto::getCateId));

28. hutool获取时间戳到秒
SignUtil.createNonceStr();

29. 根据关键字显示后10行数据：grep -A 10 关键字  文件

30. 根据关键字显示前10行数据：grep -B 10 关键字  文件

31. cat 文件 | grep 关键字或grep '关键字' 文件

32.mybatis-plus修改忽略值判断
@TableField(value = "end_time", updateStrategy = FieldStrategy.IGNORED)

33.mybatis-plus排除数据库字段
@TableField(exist = false) 

34. list转string
String.join(",", list);

35. list求和
list.stream().mapToInt(student::getScore).sum();

36.string转list
Arrays.asList(str.split(",")).stream().map(s -> (s.trim())).collect(Collectors.toList());

37. startTime <= now, endTime >= now
active.getStartTime().isBefore(now) && active.getEndTime().isAfter(now)

38. 实时更新nacos配置参数
@RefreshScope

39. swagger使用
@Api(tags = "用户接口")
@ApiOperation(value = "用户列表")

@ApiModel("配送地址")
@ApiModelProperty("地址id")

40. hutool获取客户端ip
ServletUtil.getClientIP(request)

41. linux查看安装目录
whereis nginx

42. linux查看历史使用的命令
history
linux重定向符>, >>
> 为重定向符，会把命令执行的输出内容重定向到指定的文件。>>同样为重定向符，内容会被追加到后面。
例如：nohup java -Xms128m -Xmx256m -jar test.jar --spring.profiles.active=test >>nohup.out &
linux只输出错误信息到日志文件
nohup java -jar yourProject.jar >>test.log >/dev/null 2>log & 
linux什么信息也不要
nohup java -jar yourProject.jar >>test.log >/dev/null 2>&1 &
43. hutool RSA非对称加解密
//加密
RSA rsa = new RSA(null, publicKey);
String encrypt = rsa.encryptBase64("18670346997", KeyType.PublicKey);
//解密
RSA rsa = new RSA(privateKey, null);
rsa.decryptStr(encrypt, KeyType.PrivateKey);

44. hutool SHA256算法Base64编码生成签名
Sign sign = SecureUtil.sign(SignAlgorithm.SHA256withRSA, privateKey, null);
String signStr = Base64.getEncoder().encodeToString(sign1.sign("18670346997".getBytes()))

49. fastjson签名顺序错乱的问题 Feature.OrderedField
SortedMap<String, Object> params = JSONObject.parseObject(JSONObject.toJSONString(baseDto), TreeMap.class, Feature.OrderedField);

53. hikari数据源连接池
	springboot2.0默认连接池就是hikari
	配置如下：
spring:
	datasource:
    dynamic:
        primary: supplier
        datasource: 
            supplier:
                url: jdbc:mysql://sztb-test-mysql-3ktsyq.rwlb.rds.aliyuncs.com:3306/test_supplier?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&failOverReadOnly=false&zeroDateTimeBehavior=convertToNull&transformedBitIsBoolean=true&useSSL=false
                username: test_user_j3hp0y
                password: xI8v1VdaJFMGgrfq
                driver-class-name: com.mysql.cj.jdbc.Driver
                type: com.zaxxer.hikari.HikariDataSource
                hikari:
                    minimum-idle: 5
                    maximum-pool-size: 15
                    auto-commit: true
                    idle-timeout: 30000
                    pool-name: DatebookHikariCP
                    max-lifetime: 1800000
                    connection-timeout: 30000
                    connection-test-query: SELECT 1
            pool:
                url: jdbc:mysql://sztb-test-mysql-3ktsyq.rwlb.rds.aliyuncs.com:3306/test_product_pool?serverTimezone=Asia/Shanghai&useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&failOverReadOnly=false&zeroDateTimeBehavior=convertToNull&transformedBitIsBoolean=true&useSSL=false
                username: test_user_j3hp0y
                username: test_user_j3hp0y
                password: xI8v1VdaJFMGgrfq
                driver-class-name: com.mysql.cj.jdbc.Driver
                type: com.zaxxer.hikari.HikariDataSource
                hikari:
                    minimum-idle: 5
                    maximum-pool-size: 15
                    auto-commit: true
                    idle-timeout: 30000
                    pool-name: DatebookHikariCP
                    max-lifetime: 1800000
                    connection-timeout: 30000
                    connection-test-query: SELECT 1
默认使用主数据源，需要切换可以使用@DS("数据源名称")注解切换从数据源。

54. Elasticsearch使用中文分词器 IK分词器。
Springboot集成ElasticSearch有两个客户端去操作
1. ElasticsearchOperations
特点：始终使用面向对象方式操作ES
	索引：用来存放相似文档集合
	映射：用来决定放入文档的每个字段以什么样的方式录入到ES中字段类型 分词器...
	文档：可以被索引最小单元json数据格式
2. RestHighLevelClient 和 kibanna操作一样

45.mybatis-plus or拼接查询
 queryWrapper.and(wrapper -> wrapper.eq(BpLimitAreaSku::getSaleId, 0).or().eq(BpLimitAreaSku::getSaleId, saleId));
 
46.@Transactional失效的几种情况
   a.@Transactional 应用在非 public 修饰的方法上
   b.@Transactional 注解属性 propagation 设置错误
   c.@Transactional 注解属性 rollbackFor 设置错误
   d.同一个类中方法调用，导致@Transactional失效
   e.异常被catch捕获导致@Transactional失效
   本类调用，以最外层事务为准，如果最外层方法没有事务，并且直接this.调用本类的事务方法，将导致事务失效

47.mysql联合索引失效问题
   联合索引是以最左匹配原则并且不能跳过索引中的列(不能出现中间断层)，把经常查询字段的放在最左边。
   
48. mysql执行计划explan类型type执行速度从大到小
	null>system>const>eq_ref>ref>range>index>all

51. mysql判断语句
IF(value IS NOT NULL AND value <> '', value, value1)
IFNULL(SUM(value), 0)
IFNULL(value, value1),if value = null,那么用value1，但不能包括为空的字符串
推荐用IF(value IS NULL OR value = '', value1， value)
SELECT
CASE 
	WHEN value=1 THEN '1'
	WHEN value=0 THEN '0'
END 'value'

CASE 
	value
	WHEN 1 THEN '1'
	WHEN 0 THEN '0'
END 'value'

52. mysql语句 in not in exists not exists
in exists
如果查询的两个表大小相当，那么in和exists差别不大
如果两个表A较小，B较大，小标驱动大表用exists，exists后面连接的子查询返回的是true和false，用于条件验证。
select * from A 
where exists(select 1 from B where cc=A.cc)
如果两个表A较大，B较小，用in
select * from A 
where cc in (select cc from B)

not in not exists
not in 子查询是进行全表扫描，没有用到索引，而not exists的子查询依然能使用到表上的索引
所以无论哪个表大小，用not exists 都比not in要快
select * from A 
where cc not in (select cc from B)
select * from A 
where not exists(select cc from B where cc=A.cc)

50. mysql优化
left join(左连接)：返回包括左表中的所有记录和右表中联结字段相等的记录 
inner join(内连接)：只返回两个表中联结字段相等的行
inner join > left join
select,update > insert,delete
left join on 后面加 and 条件，左边的表数据照样返回，右边会根据条件进行筛选，没有则返回null，按理说速度会大于where，在where之前执行
sql语句执行顺序
FROM > JOIN ON AND > WHERE > GROUP BY > HAVING > SELECT > DISTINCT > ORDER BY > LIMIT

55. mysql explan
1)id：id代表表的加载顺序，id值相同，从上往下执行；id不同，大的最先执行。

2)select_type: select_type代表查询类型，比如：simple、primary、subquery、derived、union、union_result

3)table: 代表哪张表

4)type：代表访问类型排列 
system>const>eq_ref>ref>range>index>ALL
日常查询至少保证达到range级别，最好能达到ref。
system：代表只有一条记录的表，比如系统表，基本上不会出现。
const：表示通过索引一次就能找到的，const用于主键(primary key)、唯一索引(unique key)。因为只匹配一行数据，所以很快。
如将主键置于where列表中，MYSQL就能将该查询转换为一个常量。
eq_ref：唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描
ref：非唯一性索引扫描，返回匹配某个单独值得所有行。本质上也是一种索引访问，它返回所有匹配某个单独值得行，
然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体。
range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引
一般就是在你的where语句中出现了between and、<、>、in等的查询这种范围扫描要比全表扫描要好，因为他只需要开始
于索引的某一点，而结束于另一点，不用扫描全部。
index：全索引扫描，index与all区别为index类型只遍历索引树。这通常比all快，因为索引文件通常比数据文件小。
(也就是说all和index都是读全表，但index是从索引中读取的，而all是从硬盘中读的。)
all：全表扫描。

5)possible_keys：显示可能应用在这张表中的索引，一个或多个。
查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用

6)key：显示实际使用的索引。

7)key_len：表示索引中使用的字节数，可以通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。
key_len显示的值为索引字段的最大可能的长度

8)ref：显示索引的哪一列被使用，有可能是常数。哪些列或常量被用于查找索引列上的值

9)rows：返回大概找到所需的记录

10)Extra：额外信息，比如：using where、using index等
using filesort：mysql没有使用索引进行排序，产生文件内排序。
using temporary：使用临时表保存中间结果，mysql在对查询结果排序时使用临时表。常见于排序order by和分组group by。
using index：表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错。
如果同时出现using where，表明索引被用来执行索引键值的查找；
如果没有出现using where，表明索引用来读取数据而非执行查询动作。

56.索引失效
1).复合索引要遵循最左匹配原则，并且不能跳过索引中的列(不能出现中间断层)
2).不能在索引列上做任何操作（计算、函数、类型转换等），会导致索引失效而转向全表扫描。
3).尽可能的使用覆盖索引(只访问索引列的查询（索引列和查询列一致)），减少select * 的使用。
4).低版本mysql在使用不等于（!=或者<>）的时候无法使用索引会导致全表扫描，高版本mysql会使用索引并且是范围(range)查找
5).低版本mysql在使用is not null是无法使用索引，高版本mysql会使用索引并且是范围(range)查找。is null是可以使用索引的。
6).少用or，用它来连接时会导致索引失效
7).字符串不加单引号也会导致索引失效。
8).sql语句模糊查询的时候左右两边都使用了通配符%号会导致索引失效，解决办法1：左边的通配符%去掉2：使用覆盖索引。
group by 分组之前必排序，会有临时表

57.mysql日志
1). 重做日志(redo log): 确保事物的持久性。redo日志记录事务执行后的状态，用来恢复写入data file的
已成功事物更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，再重启mysql服务的时候，根据redo log
进行重做，从而达到事物的持久性。
2).回滚日志(undo log)：保证数据的原子性，保存了事物发生之前的数据的一个版本也就是未提交事物的数据，可以用于回滚。
3).二进制日志(binlog)：记录事物提交的数据，用于复制，在主从复制中，从库利用主库上的binlog进行复制，实现主从同步。
4).错误日志(errorlog)：错误日志记录着mysqld启动和停止，以及服务器在运行过程中发生的错误的相关信息。
5).慢查询日志(slow query log)：慢查询日志记录执行时间过长和没有使用索引的查询语句。慢日志只会记录执行成功的语句。
默认执行时间大于10s会被记录。
6).一般查询日志(general log)：一般查询日志记录了服务器接收到的每一个查询或是命令，无论这些查询还是命令是否正确或者错误，
general log都会将其记录下来。
7).中继日志(relay log)：从数据库服务器启动I/O将主服务器的bin log日志读取过来记录到relay log里面，然后从服务器sql线程读取relay log
之日的内容并应用到服务器上，从而达到主从服务器数据的一致。

58.mysql优化步骤
1).用慢查询日志捕获查询时间长的sql
2).用explan分析耗时长的sql
3).sql数据库服务器的参数调优

59.索引优化分析
1).使用索引
2).单表查询优化：复合索引要遵循最左匹配原则。
3).关联查询优化：保证被关联表连接的字段建立索引。
4).子查询优化:in和exists使用，小表驱动大表使用exists否则使用in
5).order by 关键字优化：尽量使用Index方式排序,避免使用FileSort方式排序，复合索引要遵循最左匹配原则，对应字段升降序要一致。
6).分页查询优化
7).group by关键字优化：group by 实质是先排序后分组，复合索引要遵循最左匹配原则。
当无法使用索引时，可以增大max_length_for_sort_data参数的设置+增大sort_buffer_size参数的设置
where高于having，能使用where就不要使用having。
8).去重优化：尽量不适用distinct，可以使用group by分组达去重。

60.查询截取分析
1).开启慢查询日志，SHOW VARIABLES LIKE '%slow_query_log%';查询是否开启，set global slow_query_log=1;设置开启。
根据慢查询日志找到耗时较长的sql。
2).用show profile去分析，首先要开启show profile功能Show  variables like 'profiling';查看状态，set profiling=1;设置开启，
然后用show profiles查看结果，会显示最近查询前15条sql语句，找到其中耗时最长的语句，在使用show profile cpu,block io for query n分析sql语句在
各个过程中所消耗时间和性能，逐一去排查。如果sql语句建立连接，校验权限，语句优化，执行时间等各个阶段。	
3).开启全局查询日志set global general_log=1;命令开启，set global log_output='TABLE';使用的sql语句就会记录在mysql.general_log表里。

70.表锁(偏读)
偏向MyISAM存储引擎，开销小，加锁快；无死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。
mysql表锁两种模式：读锁（共享锁）、写锁（排它锁）
读锁会阻塞写，但是不会堵塞读。而写锁则会把读和写都堵塞。

71.行锁(偏写)
偏向Innodb存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
Innodb与MyISAM的最大不同有两点：一是支持事物；二是采用了行级锁。
无索引会导致行锁升级到表锁。
间隙锁是指范围性锁。

72.mysql主从复制两种方式，三种模式
第一种方式基于二进制日志进行复制。
原理如下：
1)master将改变的记录保存到二进制日志(bin log)中
2)slave的io线程连接master并获取二进制日志内容写入到自己的中继日志(relay log)中
3)slave的sql线程读取中继日志(relay log)中改变的记录并执行，让数据与master数据保持一致。
主从复制默认使用异步模式

第二种方式：基于gtid方式进行复制，对MySQL版本有要求，最好5.7版本以上。
gtid(global transation id)是全局事务ID由两部分组成：server_uuid和transaction_id。
server_uuid代表MySQL实例的唯一标识。
transaction_id代表该实例上已提交的事务数量。
原理如下：
1)master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。
2)slave端的i/o线程将变更的binlog，写入到本地的relay log中。
3)sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。
4)如果有记录，说明该GTID的事务已经执行，slave会忽略。
5)如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。
6)在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。
GTID的优点：
1)一个事务对应一个唯一ID，一个GTID在一个服务器上只会执行一次。
2)GTID是用来代替传统的复制方法，GTID复制与普通复制模式最大的不同就是不需要指定二级制文件名和位置
3)减少手工干预和降低服务故障时间，当主机挂了之后通过软件从众多的备机中提升一台备机为主机。
GTID复制默认使用异步模式。
三种模式
异步模式：主库在执行完客户端提交的事务后会立即将结果返给客户端，并不关心从库是否已经接受并处理。
这样会有一个问题，主库挂掉，此时主库上已经提交事务，可能并没有传到从库上，如果此时，强行将从提升为主，
可能导致新主上的数据不完整。

同步模式：当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回。
导致时间长，性能低。

半同步模式：介于同步复制与异步复制之间的一种，主库只需要等待至少一个从库节点收到，只需要从库I/O线程执行到中继日志完成即可，
主库不需要等待所有从库给主库反馈。节省了很多时间。（需要添加插件才能使用）

73.mycat作用
读写分离、数据分片、多数据源整合

74.mysql数据库分区
表的使用不受影响，还是一张表，体现在物理存储的文件上，原本一个表对应一个文件，分区之后一张表对应多个文件。
4种分区类型
range分区：根据表字段的范围进行分区，比如年份范围。
list分区：集合分区，指定具体数据进行分区，如果年份 2001,2002；2003,2004。
hash分区：根据hash算法进行分区，比如求余数。
子分区：结合上三种进行分区，比如先设置range分区，在range分区在设置子分区hash分区。
分区优点：提高查询速度。
分区缺点：并发量不高，分区键设置不灵活。

75.mysql数据库查询过程
1).客户端向mysql服务器发送一条查询请求
2).服务器首先检查查询缓存，如果命中缓存，则立即返回存储在缓存中的结果，否则进入下一个阶段
3).服务器进行SQL解析、预处理、再由优化器生成对应的执行计划。
4).mysql根据执行计划，调用存储引擎的API来执行查询
5).将结果返回给客户端，同时缓存查询结果

76.mysql数据库垂直拆分、水平拆分。
垂直拆分：把不同的表拆到不同的数据库中。按照业务将表进行分类，分布到不同的数据库上面，这样也就将压力分担到不同的数据库上。
例如：电商项目，会把用户相关表的放在一个库中，商品相关的表放在一个库中，业务交易相关的表放在一个库等。
垂直拆分优点：1.拆分后业务清晰，拆分规则明确。2.系统之间整合或扩展容易。3.数据库维护简单。
垂直拆分缺点：1.部分业务无法join关联，只能通过接口的方式去解决，提高了系统的复杂度。
2.事物处理复杂。
水平拆分：把同一个表拆分到不同的数据库中，按照数据行进行切分。
水平拆分优点：拆分规则抽象好，join操作基本可以数据库做；不存在单库大数据，高并发的性能瓶颈；
应用端改造较少；提高了系统的稳定性跟负载能力。
水平拆分缺点：拆分规则难以抽象；分片事务一致性难以解决；数据多次扩展难度跟维护量极大；跨库join性能较差。

77.mysql事物的四大特性(ACID)
1).原子性(Atomicity):事物在操作的时候要么成功，要么失败。
2).一致性(Consistency):事物在执行前后，数据都是保持一致的。
3).隔离性(Isolation):指多个事物并发执行的时候，事物内部的操作与其他事物是隔离的，各个事物之间不能相互干扰。
4).持久性(Durability):事物一旦提交，数据永久生效，不会改变。
mysql怎么保证一致性呢？
数据库通过原子性、隔离性、持久性来保证一致性。一致性是目的，原子性、隔离性、持久性是手段。通过手段来保证目的。
比如：原子性无法保证，显然一致性也无法保证。
mysql怎么保证原子性呢？
利用Innodb的undo log。undo log名为回滚日志，是实现原子性的关键，当事物回滚时能够撤销所有成功执行的sql语句，
他需要记录你要回滚的相应日志信息。
比如：
(1)当你delete一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert这条旧数据
(2)当你update一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行update操作
(3)当年insert一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行delete操作
mysql怎么保证持久性呢？
利用Innodb的redo log。redo log名为重做日志，是实现持久性的关键。Mysql是先把磁盘上的数据加载到内存中，
在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。
于是，决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。
当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，
会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。
mysql怎么保证隔离性呢？
利用表锁和行锁来实现隔离性。
78.Jenkins
持续集成工具
启动jenkins并指定端口
nohup java -jar jenkins.war --httpPort=8845
nexus3：Maven仓库管理器
79.mysql隔离级别
1).读未提交：脏读、不可重复读、幻读
2).读已提交：不可重复读、幻读
3).可重复读：幻读
4).可串行化
mysql默认隔离级别：可重复读
脏读：读取到其它事物未提交的数据。
不可重复：读取到其它事物已修改过的数据。
幻读：读取到其它事务已新增的数据。

79.数据结构及算法
1).数据结构包括：线性结构和非线性结构
线性结构：线性结构作为最常用的数据结构，其特点是数据元素之间存在一对一的线性关系；
线性结构有两种不同的存储结构，即顺序存储结构(数组)和链式存储结构(链表)。顺序存储的线性表称为顺序表，顺序表中的存储元素是连续的；
链式存储的线性表称为链表，链表中的存储元素不一定是连续的，元素节点中存放数据元素以及相邻元素的地址信息；
线性结构常见的有：数组、队列、链表和栈。
非线性结构：一对多的关系比如：树结构、图结构等。
2).冒泡排序算法:外循环控制轮数，内循环每轮的次数。
3).二分查找算法：查找的数据是有序排列，会将数据分为三个部分，左，中，右。
查找的数据大于中间数据，则从右边找；查找的数据小于中间数据，则从左边找；否则相等，
查找方式使用递归或循环的方式。
4).单向链表：查找的方向只能是一个方向，单向链表不能自我删除，需要依靠辅助节点。next指向下一个节点。
5).双向链表：可以向前或向后查找，可以自我删除。next指向下一个节点，pre指向前一个节点。
6).二叉树：每个节点最多只能有两个子节点，子节点分为左节点和右节点。
   满二叉树：如果该二叉树的所有叶子节点都在最后一层，并且节点总数=2^n-1,n为层数。满二叉树也是完全二叉树的一种。
   完全二叉树：如果该二叉树的所有叶子节点都在最后一层或者倒数第二层，而且最后一层的叶子节点在左边连续，
   倒数第二层的叶子节点在右边连续，我们称为完全二叉树。
二叉树有三种遍历方式：
第一种前序遍历：先输出父节点，在遍历左子树和右子树
第二种中序遍历：先遍历左子树，只输出父节点，在遍历右子树
第三种后序遍历：先遍历左子树，在遍历右子树，最后输出父节点
7).堆
堆是具有以下性质的完全二叉树：每个节点的值都大于或等于其左右孩子节点的值，
称为大顶堆。
每个节点的值都小于或等于其左右孩子节点的值，称为小顶堆
8).二叉查找树或二叉排序树(Binary sort(search) tree)
二叉查找树：对于二叉查找树的任何一个非叶子节点，要求左子节点的值比当前节点值小，
右子节点的值比当前节点的值大。如果相等的值，可以将该节点放在左子节点或右子节点。

80.分布式事务
强一致性->2pc->seata At模式->适应于订单服务和商品扣减库存服务，性能低，数据实时性要求高的场景
弱一致性->seata Tcc模式->适应于下订单扣减用户账户金额，性能中
最终一致性->可靠消息分为本地消息表和RocketMQ事物消息方案
本地消息表：
本地事物执行完成，然后通过定时任务将消息发送到消息中间件，消费方消费成功再讲消息删除。

RocketMQ事物消息方案：
可以使用RocketMQ来实现可靠消息，只要因为RocketMQ支持事务消息。
执行流程：
mq生产者发送事务消息给mq服务，mq服务将消息状态标记为预备状态，此时的这条消息，
消费者是无法消费到的。
mq server会回应接收成功，生产者执行本地事物，事物执行成功则自动向MQ server发送commit消息，
MQ server接收到commit消息后将消息状态标记为可消费，此时mq消费者可以正常消费。消费成功
回应ack。
如果消费失败，mq server 的ack机制会重试。重试次数超过限制则需要人工干预。
适应于执行周期长且实时性要求不高的场景。异步执行，性能高。
典型的使用场景：注册送积分，登录送优惠券等。
最终一致性->最大努力通知
最大努力通知表示发起通知方执行完本地事务后将结果通知给事务参与者。
例通过RocketMq中间件实现最大努力通知型分布式事务。
充值案列：
交互流程如下：
 1、用户请求充值系统进行充值。
 2、充值系统完成充值将充值结果发给MQ。
 3、账户系统监听MQ，接收充值结果通知，如果接收不到消息，MQ会重复发送通知。
接收到充值结果通知账户系统增加充值金额。
 4、账户系统也可以主动查询充值系统的充值结果查询接口，增加金额。
最大努力通知方案是分布式事务中对一致性要求最低的一种,适用于一些最终一致性时间敏感度低的业务；
典型的使用场景：银行通知、支付结果 通知等。

81.分布式锁
分布式锁实现一般有三种方式
1.基于数据库实现的分布式锁
数据库悲观锁或乐观锁来实现分布式锁
悲观锁的实现：查询语句后面加上for update可以通过主键锁住这条记录。
乐观锁的实现：它是基于CAS思想实现的，加个version字段，在更新修改的时候要带上version字段的值与数据的version值进行
对比，是否一样，一样则表示这条数据没有被其它事物修改。不一样则被人修改过，然后进行重试。
适应于并发不高的场景。

2.基于Redis实现的分布式锁
1).基于Redis setnx命令来加锁
2).使用Redis官网推荐的Redisson来实现分布式锁，Redisson是在原生API基础上进行了封装。
3).使用阿里巴巴提供的Jetcache开源的缓存框架，里面也提供了分布式锁的功能，tryLockAndRun()。

3.基于Zookeeper实现的分布式锁
Zookeeper分布式锁实现应用了临时顺序节点。
zk获取锁的过程
当第一个客户端请求过来时，zk客户端会创建一个持久节点locks,如果客户端1想获取锁，需要在locks节点下
创建有个临时顺序节点lock1，接着客户端1会查找locks下面所有的临时子节点，判断自己的节点lock1是不是排序最小的那个，
如果是，则成功获取锁。处理完成会删除lock1临时顺序节点，释放锁。
当客户端2请求时也会在locks创建一个临时顺序节点lock2，然后查找locks下面的所有的临时子节点，
判断自己的节点lock2是不是排序最小的那个，此时lock1最小，于是获取锁失败，客户端2会向其它靠前的节点lock1注册Watcher事件，
用来监听lock1是否存在。此时客户端2进入等待状态。


82.设计模式
1).在项目哪些地方使用到了策略设计模式？
意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换
主要解决：在有多种算法相似的情况下，使用 if...else 所带来的复杂和难以维护。
重构订单状态变更逻辑。系统中订单的状态有好多个，每一个状态对应一种业务逻辑，以前的代码按照if() else if()分支去处理，
代码臃肿且冗余。我定义订单策略的抽象类抽取共同行为和属性，再将每个订单状态的业务逻辑封装为订单策略实现类，
并放入spring的IOC中；定义一个枚举，将订单的状态和订单策略实现类的beanID进行映射。最后定义策略上下文对象，
用于交互即可。
2).单例模式
什么是单例：保证一个类只有一个实例，并且提供一个访问该全局访问点。
懒汉模式： 类初始化时,不会初始化该对象,真正需要使用的时候才会创建该对象,具备懒加载功能。
解决懒汉模式线程安全问题
双重检查锁+volatile：
⽤两次判断加同步代码块实现线程安全
volatile有两个作⽤：保证可见性和防⽌指令重排
什么是保证可见性呢：所有线程都可以得到最新的数据，这样⼀来就保证了可见性。
什么是指令重排呢，当new⼀个对象时，⽤字节码指令分析是三条指令(new、dup、invokespecial)，这三条指令可能会发⽣重排序，引⽤指向
分配地址，但对象还未创建，导致判空校验不准确。
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
        }  
    }  
    return singleton;  
    }  
}
静态内部类：当外部类被装载时，内部类并不会被装载 当使⽤到时才会被装载，且只装载⼀次。
public class Singleton {  
    private static class SingletonHolder {  
    private static final Singleton INSTANCE = new Singleton();  
    }  
    private Singleton (){}  
    public static final Singleton getInstance() {  
        return SingletonHolder.INSTANCE;  
    }  
}
枚举：枚举是最简单也是最好⽤的实现⽅式，枚举的实际是⽤final修饰的实现enum接⼝的类，因为枚举构造只能私有，所以枚举是天⽣的单例模式
因为枚举类是在第⼀次访问时才被实例化，所以它也是懒加载的。
public enum Singleton {  
    INSTANCE;  
    public void whateverMethod() {  
    }  
}

饿汉模式：类初始化时,会立即加载该对象，线程天生安全,调用效率高。
使用场景：
1、要求生产唯一序列号。
2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。
3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。
哪些用到了单例模式：spring框架默认就是单例模式， java api-Runtime。

3)工厂模式
是用工厂方法代替new操作的一种模式
典型例子：Spring IOC容器创建bean的过程是使用了工厂设计模式
4)代理模式
代理在原有代码乃至原业务流程都不修改的情况下，直接在业务流程中切入新代码，增加新功能，
这也和Spring的（面向切面编程）很相似。
举例：Spring AOP、日志打印、异常处理、事务控制、权限控制等
5)观察者模式
当对象存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知依赖它的对象。
典型例子：Spring 中listener 的实现--ApplicationListener
6)模板模式
系统中很多批量导入的业务代码冗余，且其大致操作流程相似，为了便于维护，
故而将批量导入的流程抽取至抽象类中，具体的行为抽象交给不同的业务代码实现即可。
用来解决代码重复的问题。比如. RestTemplate, JDBCTemplate，RedisTemplate。
7)外观模式
外观模式：也叫门面模式，隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。
它向现有的系统添加一个接口，用这一个接口来隐藏实际的系统的复杂性。
使用外观模式，他外部看起来就是一个接口，其实他的内部有很多复杂的接口已经被实现
例子：调用阿里短信接口、邮件接口、微信推送接口。

83. 微服务组件
1)微服务之间如何独立通讯？
同步通讯：dubbo通过rpc远程过程调用、spring cloud 通过HTTP RESTFul调用。
异步通讯：消息队列，如：RocketMQ、ActiveM、Kafka 等。

2)dubbo服务开发流程
a.maven工程中pom文件先导入dubbo依赖jar包
b.搭建nacos注册中心
c.写好服务端工程并配置dubbo服务端配置，并关联上nacos注册中心
d.服务端的实现类上添加@DubboService注解，此注解来自阿里巴巴的
e.写好客户端工程并配置dubbo客户端配置，并关联上nacos注册中心
f.在注入的服务的接口上添加@DubboReference注解

3)dubbo运行原理
a.服务容器负责启动，加载，运行服务提供者。
b.服务提供者在启动时，向注册中心注册自己提供的服务。
c.服务消费者在启动时，向注册中心订阅自己所需的服务。
d.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
e.服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
f.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。

4)负载均衡有哪些常用的算法
a.轮询算法：轮询算法按顺序把每个新的连接请求分配给下一个服务器，最终把所有请求平分给所有的服务器。轮询算法在大多数情况下都工作的不错，
但是如果负载均衡的设备在处理速度、连接速度和内存等方面不是完全均等，那么效果会更好。
b.随机算法：负载均衡方法随机的把负载分配到各个可用的服务器上，通过随机数生成算法选取一个服务器，然后把连接发送给它。
虽然许多均衡产品都支持该算法，但是它的有效性一直受到质疑，除非把服务器的可运行时间看的很重。
c.加权轮询算法：该算法中，每个机器接受的连接数量是按权重比例分配的。这是对普通轮询算法的改进，比如你可以设定：
第三台机器的处理能力是第一台机器的两倍，那么负载均衡器会把两倍的连接数量分配给第3台机器。
d.最快算法：最快算法基于所有服务器中的最快响应时间分配连接。该算法在服务器跨不同网络的环境中特别有用。
e.最少连接算法：系统把新连接分配给当前连接数目最少的服务器。该算法在各个服务器运算能力基本相似的环境中非常有效。

5).dubbo支持哪些序列化方式？
a.hessian2序列化(默认推荐)：hessian是一种跨语言的高效二进制序列化方式。但这里实际不是原生的hessian2序列化，
而是阿里修改过的hessian lite，它是dubbo RPC默认启用的序列化方式
b.json序列化：目前有两种实现，一种是采用的阿里的fastjson库，另一种是采用dubbo中自己实现的简单json库，但其实现都不是特别成熟，
而且json这种文本序列化性能一般不如上面两种二进制序列化。
c.java序列化：主要是采用JDK自带的Java序列化实现，性能很不理想。

6).dubbo支持的协议？
a.dubbo(默认)：单一长连接和NIO异步通讯，适合大并发小数据量的服务调用，以及消费者远大于提供者。
传输协议 TCP，异步，Hessian 序列化;
b.rmi：采用JDK标准的rmi协议实现，传输参数和返回参数对象需要实现Serializable接口，
使用java标准序列化机制，使用阻塞式短连接，传输数据包大小混合，消费者和提供者个数差不多，
可传文件，传输协议 TCP。多个短连接，TCP 协议传输，同步传输，适用常规的远程服务调用和 rmi 互操作。
在依赖低版本的 Common-Collections包，java 序列化存在安全漏洞;
c.基于WebService 的远程调用协议，集成 CXF 实现，提供和原生 WebService 的互操作。
多个短连接，基于 HTTP 传输，同步传输，适用系统集成和跨语言调用;
d.基于 Http 表单提交的远程调用协议，使用Spring的HttpInvoke 实现。多个短连接，传输协议 HTTP，
传入参数大小混合，提供者个数多于消费者，需要给应用程序和浏览器 JS 调用;
e.redis：基于redis实现的RPC协议

7).spring cloud和dubbo有哪些区别
dubbo通过RPC远程过程调用，是二进制传输，占用带宽会少一点。spring cloud通过HTTP RESTFul调用，
是http传输，占用带宽会多一点，
同时使用 http 协议一般会使用 JSON 报文，消耗会更大。
Spring Cloud 抛弃了 Dubbo 的 RPC 通信，采用的是基于 HTTP 的 REST 方式。

8).dubbo自动重试机制
Dubbo在调用服务不成功时，默认会重试2次。Dubbo的路由机制，会把超时的请求路由到其他机器上，
而不是本机尝试，所以 dubbo的重试机制也能一定程度的保证服务的质量。

9).注册中心宕机，服务间是否可以继续通讯？
可以通信的，启动dubbo时，消费者会从注册中心拉取注册的生产者的地址接口等数据，缓存在本地。
每次调用时，按照本地存储的地址进行调用;

10).微服务注册中心
用来处理服务注册与发现
Eureka: 
Neflix下面的
目前阶段已经停更了，所以现在不推荐使用了。
Nacos:微服务架构中的注册中心和配置中心。
运行原理基本一致：
服务提供者把自己的协议地址注册到注册服务中心,
服务消费者从注册服务中心查询服务提供者提供的地址，
服务消费者根据提供的服务地址去访问服务提供者。

10).微服务注册中心
用来处理服务注册与发现
Eureka: 
Neflix下面的
目前阶段已经停更了，所以现在不推荐使用了。
Nacos:微服务架构中的注册中心和配置中心。
运行原理基本一致：
服务提供者把自己的协议地址注册到注册服务中心,
服务消费者从注册服务中心查询服务提供者提供的地址，
服务消费者根据提供的服务地址去访问服务提供者。

11).微服务调用
Feign：
Neflix下面的
目前阶段已经停更了，所以现在不推荐使用了。
OpenFeign:spring-cloud的子项目，是在Feign基础上做了升级，里面都内置了
Ribbon，都是加在消费端的注解，让消费端可以调用其他生产者的服务。

12).服务断路器
Hystrix：
Neflix下面的
目前阶段已经停更了，所以现在不推荐使用了。
sentienl：是阿里巴巴开源的项目，提供了流量控制，熔断降级，系统负载保护等多个维度来保障服务之间
的稳定性。有自己的控制台可以查看监控。

13).服务网关
zuul：
Neflix下面的
目前阶段已经停更了，所以现在不推荐使用了。
gateway：spring-cloud的子项目。Spring Cloud Gateway 使用的Webflux中的reactor-netty响应式编程组件，
底层使用了Netty通讯框架。
动态路由：能够匹配任何请求属性
可以对路由制定断言和过滤
集成Hystrix的断路器功能
集成spring cloud 服务发现功能
易于编写的断言和过滤器
请求限流功能
支持路径重写。
三大核心概念：路由、断言、过滤。
路由：路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由
断言：开发人员可以匹配HTTP请求中的所有内容（例如请求头或请求参数），如果请求与断言相匹配则进行路由
过滤：可以在请求被路由前或者之后对请求进行修改。

14).服务配置中心
Config：默认在git做全局配置，只能手动去刷新配置。
Nacos: 自动刷新配置只要加上@RefreshScope即可。

84. 生产环境服务器变慢，如何诊断处理？
1、 使用 top 指令，服务器中 CPU 和 内存的使用情况，-H 可以按 CPU 使用率降序，-M 内存使用率降序。
排除其他进程占用过高的硬件资源，对 Java 服务造成影响。

2、 如果发现 CPU 使用过高，可以使用 top 指令查出 JVM 中占用 CPU 过高的线程，
通过 jstack 找到对应的线程代码调用，排查出问题代码。

3、 如果发现内存使用率比较高，可以 dump 出 JVM 堆内存，
然后借助 MAT 进行分析，查出大对象或者占用最多的对象来自哪里，为什么会长时间占用这么多；如果 dump 出的堆内存文件正常，此时可以考虑堆外内存被大量使用导致出现问题，需要借助操作系统指令 pmap 查出进程的内存分配情况、gdb dump 出具体内存信息、perf 查看本地函数调用等。

4、 如果 CPU 和 内存使用率都很正常，那就需要进一步开启 GC 日志，
分析用户线程暂停的时间、各部分内存区域 GC 次数和时间等指标
可以借助 jstat 或可视化工具 GCeasy 等，如果问题出在 GC 上面的话，
考虑是否是内存不够、根据垃圾对象的特点进行参数调优、使用更适合的垃圾收集器；
分析 jstack 出来的各个线程状态。如果问题实在比较隐蔽，考虑是否可以开启 jmx，使用 visualmv 等可视化工具远程监控与分析。

85. RocketMQ相关知识
1).RocketMQ是什么？
RocketMQ作为一款纯java、分布式、队列模型的开源消息中间件，支持事务消息、顺序消息、批量消息、定时消息、消息回溯等功能。
2).RocketMQ优点
支持事务型消息（消息发送和 DB 操作保持两方的最终一致性，RabbitMQ 和 Kafka 不支持）
支持结合 RocketMQ 的多个系统之间数据最终一致性（多方事务，二方事务是前提）
支持 18 个级别的延迟消息
支持指定次数和时间间隔的失败消息重发
支持 Consumer 端 Tag 过滤，减少不必要的网络传输
支持重复消费
3).RocketMQ主要四大核心 
3.1).NameServer(名称服务)
名称服务器（NameServer）用来保存 Broker 相关元信息并给 Producer 和 Consumer 查找Broker 信息。
NameServer 被设计成几乎无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。
每个 Broker 在启动的时候会到 NameServer 注册，Producer 在发送消息前会根据 Topic 到NameServer 获取到 Broker 的路由信息，
进而和Broker取得连接。Consumer 也会定时获取 Topic 的路由信息。
3.1.1. 高可用保障
Broker 在启动时向所有 NameServer 注册（主要是服务器地址等） ，生产者在发送消息之前先从NameServer 
获取 Broker 服务器地址列表（消费者一样），然后根据负载均衡算法从列表中选择一台服务器进行消息发送。
NameServer 与每台 Broker 服务保持长连接，并间隔 30S 检查 Broker 是否存活，如果检测到Broker 宕机，
则从路由注册表中将其移除，这样就可以实现 RocketMQ 的高可用。

3.2)Broker(消息服务器)
消息服务器（Broker）是消息存储中心，主要作用是接收来自 Producer 的消息并存储，Consumer 从这里取得消息。它还存储与消息相关的元数据，
包括用户组、消费进度偏移量、队列信息等。从部署结构图中可以看出 Broker 有 Master 和 Slave 两种类型，Master 既可以写又可以读，Slave不可以写只可以读。
3.2.1 部署方式
Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，
Master与Slave的对应关系通过指定相同的Broker Name，不同的BrokerId来定义，BrokerId为0表Master，非0表示Slave。Master也可以部署多个。
从物理结构上看 Broker 的集群部署方式有四种：单 Master 、多 Master 、多 Master 多Slave（同步刷盘）、多 Master多 Slave（异步刷盘）。
3.2.1.1 单 Master
这种方式一旦 Broker 重启或宕机会导致整个服务不可用，这种方式风险较大，所以显然不建议线上环境使用。
3.2.1.2 多 Master
所有消息服务器都是 Master ，没有 Slave 。这种方式优点是配置简单，单个 Master 宕机或重启维护对应用无影响。
缺点是单台机器宕机期间，该机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受影响。
3.2.1.3 多 Master 多 Slave（异步复制）
每个 Master 配置一个 Slave，所以有多对 Master-Slave，消息采用异步复制方式，主备之间有毫秒级消息延迟。
这种方式优点是消息丢失的非常少，且消息实时性不会受影响，Master 宕机后消费者可以继续从 Slave 消费，中间的过程对用户应用程序透明，
不需要人工干预，性能同多 Master 方式几乎一样。缺点是 Master 宕机时在磁盘损坏情况下会丢失极少量消息。
3.2.1.4 多 Master 多 Slave（同步双写）
每个 Master 配置一个 Slave，所以有多对 Master-Slave ，消息采用同步双写方式，主备都写成功才返回成功。
这种方式优点是数据与服务都没有单点问题，Master 宕机时消息无延迟，服务与数据的可用性非常高。缺点是性能相对异步复制方式略低，发送消息的延迟会略高。
3.2.2 高可用保障
每个Broker与Name Server集群中的所有节点建立长连接，定时(每隔30s)注册Topic信息到所有Name Server。
Name Server定时(每隔10s)扫描所有存活broker的连接，如果Name Server超过2分钟没有收到心跳，则Name Server断开与Broker的连接。

3.3)生产者（Producer）
也称为消息发布者，负责生产并发送消息至 Topic。
生产者向brokers发送由业务应用程序系统生成的消息。RocketMQ提供了发送：同步、异步和单向（one-way）的多种范例。
3.3.1 同步发送
同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。
3.3.2 异步发送
异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，
例如用户视频上传后通知启动转码服务。假如过一段时间检测到某个信息发送失败，可以选择重新发送。
3.3.3 单向发送
单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。

3.4).消费者（Consumer）
也称为消息订阅者，负责从 Topic 接收并消费消息。
消费者从brokers那里拉取信息并将其输入应用程序。
3.4.1 消费者组
消费者组（Consumer Group）一类 Consumer 的集合名称，这类 Consumer 通常消费同一类消息并且消费逻辑一致，
所以将这些 Consumer 分组在一起。消费者组与生产者组类似，都是将相同角色的分组在一起并命名。
RocketMQ中的消息有个特点，同一条消息，只能被某一消费组其中的一台机器消费，但是可以同时被不同的消费组消费。
3.4.2 高可用保障
Consumer与Name Server集群中的其中一个节点(随机选择)建立长连接，定期从Name Server取Topic路由信息，
并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，
也可以从Slave订阅消息，订阅规则由Broker配置决定。
Consumer每隔30s从Name server获取topic的最新队列情况，这意味着Broker不可用时，Consumer最多最需要30s才能感知。
Consumer每隔30s（由ClientConfig中heartbeatBrokerInterval决定）向所有关联的broker发送心跳，
Broker每隔10s扫描所有存活的连接，若某个连接2分钟内没有发送心跳数据，则关闭连接；
并向该Consumer Group的所有Consumer发出通知，Group内的Consumer重新分配队列，然后继续消费。
当Consumer得到master宕机通知后，转向slave消费，slave不能保证master的消息100%都同步过来了，
因此会有少量的消息丢失。但是一旦master恢复，未同步过去的消息会被最终消费掉。

5).RocketMQ运行流程
a. NameServer 先启动
b. Broker 启动时向 NameServer 注册
c. 生产者在发送某个主题的消息之前先从 NamerServer 获取 Broker 服务器地址列表（有可能是集群），
然后根据负载均衡算法从列表中选择一台Broker 进行消息发送。
d. NameServer 与每台 Broker 服务器保持长连接，并间隔 30S 检测 Broker 是否存活，
如果检测到Broker 宕机（使用心跳机制， 如果检测超120S），则从路由注册表中将其移除。
e. 消费者在订阅某个主题的消息之前从 NamerServer 获取 Broker 服务器地址列表（有可能是集群），
但是消费者选择从 Broker 中 订阅消息，订阅规则由 Broker 配置决定

6).RocketMQ由哪些角色组成，每个角色作用和特点是什么？
角色作用Nameserver无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。
Producer消息生产者，负责发消息到Broker。
Broker就是MQ本身，负责收发消息、持久化消息等。
Consumer消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。

7).RocketMQ消费模式有几种？
消费模型由Consumer决定，消费维度为Topic。
集群消费
1.一条消息只会被同Group中的一个Consumer消费
2.多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据
广播消费
消息将对一 个Consumer Group 下的各个 Consumer 实例都消费一遍。即即使这些 Consumer 属于同一个Consumer Group ，
消息也会被 Consumer Group 中的每个 Consumer 都消费一次。
Rocket详情知识：https://blog.csdn.net/qq_21040559/article/details/122703715
Rocket面试题：https://blog.csdn.net/qq_27828675/article/details/115248974




